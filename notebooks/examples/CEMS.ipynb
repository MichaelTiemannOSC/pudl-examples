{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with EPA CEMS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CEMS or **Continusous Emissions Monitoring Data** is a product of the EPA's Air Emission Measurement Center / Clean Air Market Programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website: https://www.epa.gov/emc/emc-continuous-emission-monitoring-systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The following kernels enable interaction with the CEMS dataset through pudl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# 3rd party libraries\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# Local libraries\n",
    "import pudl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "#display(pudl_settings)\n",
    "\n",
    "ferc1_engine = sa.create_engine(pudl_settings['ferc1_db'])\n",
    "#display(ferc1_engine)\n",
    "\n",
    "pudl_engine = sa.create_engine(pudl_settings['pudl_db'])\n",
    "#display(pudl_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#pudl_engine.table_names()\n",
    "pudl_out = pudl.output.pudltabl.PudlTabl(pudl_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing CEMS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CEMS dataset is enormous! It contains hourly emissions data on an XXXX basis between YEAR and 2019, meaning that the full dataset is close to a billion rows and 100GB. That's a lot to store on your computer when you may only need a fraction for analysis. This'll help ensure you've got the underlying data you need saved to your computer and teach you how to access it programatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make sure you've downloaded the appropriate raw data (and only that).\n",
    "\n",
    "Information about when / how to get the CEMS files and whether they were included in your initial download of pudl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Select a subset of the raw data using Dask\n",
    "\n",
    "Dask is a python package that parallelizes pandas dataframes so that you can access larger-than-memory data. With Dask, you can select the subset of CEMS data that you'd like to analyse *before* loading the data into a dataframe. While in Dask, you can interact with the data as if it were in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a year or years to observe\n",
    "year = 2018\n",
    "\n",
    "# Locate the data for the given year/s on your hard drive.\n",
    "epacems_path = (pudl_settings['parquet_dir'] + f'/epacems/year={year}')\n",
    "\n",
    "# Create a Dask object for preliminary data interaction\n",
    "cems_dd = dd.read_parquet(epacems_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can learn things about the data such as column names and datatypes. If you take a look at the length of the Dask dataframe, you'll understand why we're not in pandas yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36768792"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cems_dd) # This shows how many rows!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plant_id_eia</th>\n",
       "      <th>unitid</th>\n",
       "      <th>operating_datetime_utc</th>\n",
       "      <th>operating_time_hours</th>\n",
       "      <th>gross_load_mw</th>\n",
       "      <th>steam_load_1000_lbs</th>\n",
       "      <th>so2_mass_lbs</th>\n",
       "      <th>so2_mass_measurement_code</th>\n",
       "      <th>nox_rate_lbs_mmbtu</th>\n",
       "      <th>nox_rate_measurement_code</th>\n",
       "      <th>nox_mass_lbs</th>\n",
       "      <th>nox_mass_measurement_code</th>\n",
       "      <th>co2_mass_tons</th>\n",
       "      <th>co2_mass_measurement_code</th>\n",
       "      <th>heat_content_mmbtu</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>unit_id_epa</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=49</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int32</td>\n",
       "      <td>object</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float32</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float32</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float32</td>\n",
       "      <td>category[unknown]</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>int32</td>\n",
       "      <td>category[known]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-parquet, 49 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               plant_id_eia  unitid operating_datetime_utc operating_time_hours gross_load_mw steam_load_1000_lbs so2_mass_lbs so2_mass_measurement_code nox_rate_lbs_mmbtu nox_rate_measurement_code nox_mass_lbs nox_mass_measurement_code co2_mass_tons co2_mass_measurement_code heat_content_mmbtu facility_id unit_id_epa            state\n",
       "npartitions=49                                                                                                                                                                                                                                                                                                                                  \n",
       "                      int32  object    datetime64[ns, UTC]              float32       float32             float32      float32         category[unknown]            float32         category[unknown]      float32         category[unknown]       float32         category[unknown]            float32       int32       int32  category[known]\n",
       "                        ...     ...                    ...                  ...           ...                 ...          ...                       ...                ...                       ...          ...                       ...           ...                       ...                ...         ...         ...              ...\n",
       "...                     ...     ...                    ...                  ...           ...                 ...          ...                       ...                ...                       ...          ...                       ...           ...                       ...                ...         ...         ...              ...\n",
       "                        ...     ...                    ...                  ...           ...                 ...          ...                       ...                ...                       ...          ...                       ...           ...                       ...                ...         ...         ...              ...\n",
       "                        ...     ...                    ...                  ...           ...                 ...          ...                       ...                ...                       ...          ...                       ...           ...                       ...                ...         ...         ...              ...\n",
       "Dask Name: read-parquet, 49 tasks"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cems_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plant_id_eia',\n",
       " 'unitid',\n",
       " 'operating_datetime_utc',\n",
       " 'operating_time_hours',\n",
       " 'gross_load_mw',\n",
       " 'steam_load_1000_lbs',\n",
       " 'so2_mass_lbs',\n",
       " 'so2_mass_measurement_code',\n",
       " 'nox_rate_lbs_mmbtu',\n",
       " 'nox_rate_measurement_code',\n",
       " 'nox_mass_lbs',\n",
       " 'nox_mass_measurement_code',\n",
       " 'co2_mass_tons',\n",
       " 'co2_mass_measurement_code',\n",
       " 'heat_content_mmbtu',\n",
       " 'facility_id',\n",
       " 'unit_id_epa',\n",
       " 'state']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cems_dd.columns.tolist()\n",
    "# For a further information about the contents of each column, see:\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know what's available, you'll want to pick which columns you'd like to work with and aggregate rows if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the columns you'd like to include in your analysis\n",
    "my_cols = [\n",
    "    'state',\n",
    "    'plant_id_eia', \n",
    "    'unitid',\n",
    "    'so2_mass_lbs', \n",
    "    'nox_mass_lbs', \n",
    "    'co2_mass_tons',\n",
    "]\n",
    "\n",
    "# Select emissions data are grouped by state, plant_id and unit_id\n",
    "# goes BONKERS when I try and add state to the groupby\n",
    "my_cems_dd = (\n",
    "    dd.read_parquet(epacems_path, columns=my_cols)\n",
    "    .assign(state=lambda x: x['state'].astype('string'))\n",
    "    .groupby(['plant_id_eia', 'unitid', 'state'])[\n",
    "         ['so2_mass_lbs', 'nox_mass_lbs', 'co2_mass_tons']]\n",
    "    .sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Transfer your desired data to pandas\n",
    "\n",
    "Now that you've selected the data you want to work with, we'll transfer it to pandas so that all rows are accessible. It'll take a moment to run because there are so many rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aesharpe/miniconda3/envs/pudl-dev/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 58018 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas dataframe out of your Dask dataframe and add a column to indicate the year the data are coming from\n",
    "# This may take a moment to run...\n",
    "client = Client()\n",
    "my_cems_df = (\n",
    "    client.compute(my_cems_dd)\n",
    "    .result()\n",
    "    .assign(year=year)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEMS access via DD client? why need that rather than \n",
    "# just strait pandas.read_parquet()\n",
    "\n",
    "client = Client()\n",
    "cols = ['plant_id_eia', 'unitid',\n",
    "        'so2_mass_lbs', 'nox_mass_lbs', 'co2_mass_tons']\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "for yr in range(2018, 2019):\n",
    "    epacems_path = (pudl_settings['parquet_dir'] + f'/epacems/year={yr}')\n",
    "    cems_dd = (\n",
    "        dd.read_parquet(epacems_path, columns=cols)\n",
    "        .groupby(['plant_id_eia', 'unitid'])[\n",
    "            ['so2_mass_lbs', 'nox_mass_lbs', 'co2_mass_tons']]\n",
    "        .sum())\n",
    "    cems_df = (\n",
    "        client.compute(cems_dd)\n",
    "        .result()\n",
    "        .assign(year=yr))\n",
    "    out_df = pd.concat([out_df, cems_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epacems_path = (pudl_settings['parquet_dir'] + f'/epacems/year=2018')\n",
    "#pd.read_parquet(epacems_path)\n",
    "cems_dd = dd.read_parquet(epacems_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plant_id_eia',\n",
       " 'unitid',\n",
       " 'operating_datetime_utc',\n",
       " 'operating_time_hours',\n",
       " 'gross_load_mw',\n",
       " 'steam_load_1000_lbs',\n",
       " 'so2_mass_lbs',\n",
       " 'so2_mass_measurement_code',\n",
       " 'nox_rate_lbs_mmbtu',\n",
       " 'nox_rate_measurement_code',\n",
       " 'nox_mass_lbs',\n",
       " 'nox_mass_measurement_code',\n",
       " 'co2_mass_tons',\n",
       " 'co2_mass_measurement_code',\n",
       " 'heat_content_mmbtu',\n",
       " 'facility_id',\n",
       " 'unit_id_epa',\n",
       " 'state']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cems_dd.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
