{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalyst Cooperative Jupyter Notebook Template\n",
    "This notebook lays out a standard format and some best practices for creating interactive / exploratory notebooks which can be relatively easily shared between different PUDL users, and turned into reusable Python modules for integration into our underlying Python packages.\n",
    "\n",
    "## Begin with a narrative outline\n",
    "Each notebook should start with a brief explanation (in Markdown) explaining the purpose of the analysis, and outlining the different stages / steps which are taken to accomplish the analysis.\n",
    "As the analysis develops, you can add new sections or details to this section.\n",
    "\n",
    "## Notebooks should be runnable\n",
    "Insofar as it's possible, another PUDL user who has cloned the repository that the notebook is part of should be able to update their `pudl-dev` conda environment, open the notebook, and run all cells successfully.\n",
    "If there are required data or other prerequisites that the notebook cannot manage on its own -- like a file that needs to be downloaded by hand and placed in a particular location -- those steps should be laid out clearly at the beginning of the notebook.\n",
    "\n",
    "## Avoid Troublesome Elements\n",
    "\n",
    "### Don't hardcode passwords or access tokens\n",
    "Most of our work is done in public Github repositories.\n",
    "No authentication information should ever appear in a notebook.\n",
    "These values can be stored in environment variables on your local computer.\n",
    "\n",
    "### Do not hardocde values, especially late in the notebook\n",
    "If the analysis depends on particular choices of input values, those should be called out explicitly at the beginning of the notebook.\n",
    "(NB: We should explore ways to parameterize notebooks, [papermill](https://papermill.readthedocs.io/en/latest/) is one tool that does this).\n",
    "\n",
    "### Don't hardcode absolute file paths\n",
    "If anyone is going to be able to use the notebook, the files it uses will need to be stored somewhere that makes sense on both your and other computers.\n",
    "We assume that anyone using this template has the PUDL package installed, and has a local PUDL data management environment set up.\n",
    "  * Input data that needs to be stored on disk and accessed via a shared location should be saved under `<PUDL_IN>/data/local/<data_source>/`.\n",
    "  * Intermediate saved data products (e.g. a pickled result of a computationally intensive process) and results should be saved to a location relative to the notebook, and within the directory hierarchy of the repository that the notebook is part of.\n",
    "  \n",
    "### Don't require avoidable long-running computations\n",
    "Consider persisting to disk the results of computations that take more than a few minutes, if the outputs are small enough to be checked into the repository and shared with other users.\n",
    "Only require the expensive computation to be run if this pre-computed output is not available.\n",
    "\n",
    "### Don't litter\n",
    "Don't leave lots of additional code laying around, even commented out, \"just in case\" you want to look at it again later.\n",
    "Notebooks need to be relatively linear in the end, even though the thought processes and exploratory analyses that generate them may not be.\n",
    "Once you have a working analysis, either prune those branches, or encapsulate them as options within functions.\n",
    "\n",
    "### Don't load unneccesary libraries\n",
    "Only import libraries which are required by the notebook, to avoid unnecessary dependencies.\n",
    "If your analysis requires a new library that isn't yet part of the shared `pudl-dev` environment, add it to the `devtools/environment.yml` file so that others will get it when they update their environment.\n",
    "\n",
    "## Related Resources:\n",
    "Lots of these guidelines are taken directly from Emily Riederer's post: [RMarkdown Driven Development](https://emilyriederer.netlify.app/post/rmarkdown-driven-development/).\n",
    "For more in depth explanation of the motivations behind this layout, do go check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "* Because it's very likely that you will be editing the PUDL Python packages or your own local module under development while working in the notebook, use the %autoreload magic with autoreload level 2 to ensure that any changes you've made in those files are always reflected in the code that's running in the notebook.\n",
    "* Put all import statements at the top of the notebook, so everyone can see what its dependencies are up front, and so that if an import is going to fail, it fails early, before the rest of the notebook is run.\n",
    "* Try to avoid importing individual functions and classes from deep within packages, as it may not be clear to other users where those elements came from, later in the notebook, and also to minimize the chance of namespace collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# 3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "\n",
    "# Local libraries\n",
    "import pudl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Display Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Python Logging facilities\n",
    "* Using a logger from the beginning will make the transition into the PUDL package easier.\n",
    "* Creating a logging handler here will also allow you to see the logging output coming from PUDL and other underlying packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions\n",
    "In many cases, the eventual product of a notebook analysis is going to be the creation of new, reusable functions that are integrated into the underlying PUDL code. You should begin the process of accumulating and organizing those functions as soon as you notice repeated patterns in your code.\n",
    "* Functions should be used to encapsulate any potentially reusable code.\n",
    "* Functions should be defined immediately after the imports, to avoid accidental dependence on zombie variables that are defined further down in the code\n",
    "* While they may evolve over time, having brief docstrings explaining what they do will help others understand them.\n",
    "* If there's a particular type of plot or visualization that is made repeatedly in the notebook, it's good to parameterize and functionalize it here too, so that as you refine the presentation of the data and results, those improvements can be made in a single place, and shown uniformly throughout the notebook.\n",
    "* As these functions mature and become more general purpose tools, you will probably want to start migrating them into their own local module, under a `src` directory in the same directory as the notebook. You will want to import this module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy EIA 861 ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_etl_eia(eia_inputs, pudl_settings):\n",
    "    \"\"\"\n",
    "    This is a dummy function that runs the first part of the EIA ETL\n",
    "    process -- everything up until the entity harvesting begins. For\n",
    "    use in this notebook only.\n",
    "\n",
    "    \"\"\"\n",
    "    eia860_tables = eia_inputs[\"eia860_tables\"]\n",
    "    eia860_years = eia_inputs[\"eia860_years\"]\n",
    "    eia861_tables = eia_inputs[\"eia861_tables\"]\n",
    "    eia861_years = eia_inputs[\"eia861_years\"]\n",
    "    eia923_tables = eia_inputs[\"eia923_tables\"]\n",
    "    eia923_years = eia_inputs[\"eia923_years\"]\n",
    "\n",
    "    # generate CSVs for the static EIA tables, return the list of tables\n",
    "    #static_tables = _load_static_tables_eia(datapkg_dir)\n",
    "\n",
    "    # Extract EIA forms 923, 860\n",
    "    eia860_raw_dfs = pudl.extract.eia860.Extractor().extract(eia860_years, testing=True)\n",
    "    eia861_raw_dfs = pudl.extract.eia861.Extractor().extract(eia861_years, testing=True)\n",
    "    eia923_raw_dfs = pudl.extract.eia923.Extractor().extract(eia923_years, testing=True)\n",
    "\n",
    "    # Transform EIA forms 860, 861, 923\n",
    "    eia860_transformed_dfs = pudl.transform.eia860.transform(eia860_raw_dfs, eia860_tables=eia860_tables)\n",
    "    eia861_transformed_dfs = pudl.transform.eia861.transform(eia861_raw_dfs, eia861_tables=eia861_tables)\n",
    "    eia923_transformed_dfs = pudl.transform.eia923.transform(eia923_raw_dfs, eia923_tables=eia923_tables)\n",
    "\n",
    "    # create an eia transformed dfs dictionary\n",
    "    eia_transformed_dfs = eia860_transformed_dfs.copy()\n",
    "    eia_transformed_dfs.update(eia861_transformed_dfs.copy())\n",
    "    eia_transformed_dfs.update(eia923_transformed_dfs.copy())\n",
    "\n",
    "    # convert types..\n",
    "    eia_transformed_dfs = pudl.helpers.convert_dfs_dict_dtypes(eia_transformed_dfs, 'eia')\n",
    "\n",
    "    return eia860_raw_dfs, eia861_raw_dfs, eia923_raw_dfs, eia_transformed_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Notebook Parameters\n",
    "If there are overarching parameters which determine the nature of the analysis -- which US states to look at, which utilities are of interest, a particular start and end date -- state those clearly at the beginning of the analysis, so that they can be referred to by the rest of the notebook and easily changed if need be.\n",
    "* If the analysis depends on local (non-PUDL managed) datasets, define the paths to those data here.\n",
    "* If there are external URLs or other resource locations that will be accessed, define those here as well.\n",
    "* This is also where you should create your `pudl_settings` dictionary and connections to your local PUDL databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pudl_in': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR',\n",
       " 'data_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/data',\n",
       " 'settings_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/settings',\n",
       " 'pudl_out': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR',\n",
       " 'sqlite_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/sqlite',\n",
       " 'parquet_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/parquet',\n",
       " 'datapkg_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/datapkg',\n",
       " 'notebook_dir': '/Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/notebook',\n",
       " 'ferc1_db': 'sqlite:////Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/sqlite/ferc1.sqlite',\n",
       " 'pudl_db': 'sqlite:////Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/sqlite/pudl.sqlite'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:////Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/sqlite/ferc1.sqlite)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:////Users/aesharpe/Desktop/Work/Catalyst_Coop/PUDL_DIR/sqlite/pudl.sqlite)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "display(pudl_settings)\n",
    "\n",
    "ferc1_engine = sa.create_engine(pudl_settings['ferc1_db'])\n",
    "display(ferc1_engine)\n",
    "\n",
    "pudl_engine = sa.create_engine(pudl_settings['pudl_db'])\n",
    "display(pudl_engine)\n",
    "\n",
    "# Is there other external data you need to pull in?\n",
    "# If so, put it in a (relatively) standard place on the filesystem.\n",
    "my_new_data_url = \"https://mynewdata.website.gov/path/to/new/data.csv\"\n",
    "my_new_datadir = pathlib.Path(pudl_settings[\"data_dir\"]) / \"local/new_data_source\"\n",
    "\n",
    "# Store API keys and other secrets in environment variables\n",
    "# and read them in here, if needed:\n",
    "# API_KEY_EIA = os.environ[\"API_KEY_EIA \"]\n",
    "# API_KEY_FRED = os.environ[\"API_KEY_FRED \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* Given the above parameters and functions, it should now be possible to load the required data into local variables for further wrangling, analysis, and visualization.\n",
    "* If the data is not yet present on the machine of the person running the notebook, this step should also acquire the data from its original source, and place it in the appropriate location under `<PUDL_IN>/data/local/`.\n",
    "* If there are steps which have to be done manually here, put them first so that they fail first if the user hasn't read the instructions, and they can fix the situation before a bunch of other work gets done. Try to minimize the amount of work in the filesystem that has to be done manually though.\n",
    "* If this process takes a little while, don't be shy about producing `logging` output.\n",
    "* Using the `%%time` cell magic can also help users understand which pieces of work / data acquisition are hard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIA 861 (2010-2018)\n",
    "* Not yet fully integrated into PUDL\n",
    "* Post-transform harvesting process isn't compatible w/ EIA 861 structure\n",
    "* Only getting the `sales_eia861`, `balancing_authority_eia861`, and `service_territory_eia861` tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Already Transformed EIA 861 DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No years given. Not extracting eia860 spreadsheet data.\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2010\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2011\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2012\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2013\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2014\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2015\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2016\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2017\n",
      "Loading dataframe for eia861 advanced_metering_infrastructure_eia861 2018\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2010\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2011\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2012\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2013\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2014\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2015\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2016\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2017\n",
      "Loading dataframe for eia861 balancing_authority_eia861 2018\n",
      "No page for eia861 demand_response_eia861 2010\n",
      "No page for eia861 demand_response_eia861 2011\n",
      "No page for eia861 demand_response_eia861 2012\n",
      "Loading dataframe for eia861 demand_response_eia861 2013\n",
      "Loading dataframe for eia861 demand_response_eia861 2014\n",
      "Loading dataframe for eia861 demand_response_eia861 2015\n",
      "Loading dataframe for eia861 demand_response_eia861 2016\n",
      "Loading dataframe for eia861 demand_response_eia861 2017\n",
      "Loading dataframe for eia861 demand_response_eia861 2018\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2010\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2011\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2012\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2013\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2014\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2015\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2016\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2017\n",
      "Loading dataframe for eia861 demand_side_management_eia861 2018\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2010\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2011\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2012\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2013\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2014\n",
      "Loading dataframe for eia861 distributed_generation_eia861 2015\n",
      "No page for eia861 distributed_generation_eia861 2016\n",
      "No page for eia861 distributed_generation_eia861 2017\n",
      "No page for eia861 distributed_generation_eia861 2018\n",
      "No page for eia861 distribution_systems_eia861 2010\n",
      "No page for eia861 distribution_systems_eia861 2011\n",
      "No page for eia861 distribution_systems_eia861 2012\n",
      "No page for eia861 distribution_systems_eia861 2013\n",
      "No page for eia861 distribution_systems_eia861 2014\n",
      "No page for eia861 distribution_systems_eia861 2015\n",
      "Loading dataframe for eia861 distribution_systems_eia861 2016\n",
      "Loading dataframe for eia861 distribution_systems_eia861 2017\n",
      "Loading dataframe for eia861 distribution_systems_eia861 2018\n",
      "No page for eia861 dynamic_pricing_eia861 2010\n",
      "No page for eia861 dynamic_pricing_eia861 2011\n",
      "No page for eia861 dynamic_pricing_eia861 2012\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2013\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2014\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2015\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2016\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2017\n",
      "Loading dataframe for eia861 dynamic_pricing_eia861 2018\n",
      "No page for eia861 frame_eia861 2010\n",
      "No page for eia861 frame_eia861 2011\n",
      "No page for eia861 frame_eia861 2012\n",
      "No page for eia861 frame_eia861 2013\n",
      "No page for eia861 frame_eia861 2014\n",
      "No page for eia861 frame_eia861 2015\n",
      "Loading dataframe for eia861 frame_eia861 2016\n",
      "Loading dataframe for eia861 frame_eia861 2017\n",
      "Loading dataframe for eia861 frame_eia861 2018\n",
      "Loading dataframe for eia861 green_pricing_eia861 2010\n",
      "Loading dataframe for eia861 green_pricing_eia861 2011\n",
      "Loading dataframe for eia861 green_pricing_eia861 2012\n",
      "No page for eia861 green_pricing_eia861 2013\n",
      "No page for eia861 green_pricing_eia861 2014\n",
      "No page for eia861 green_pricing_eia861 2015\n",
      "No page for eia861 green_pricing_eia861 2016\n",
      "No page for eia861 green_pricing_eia861 2017\n",
      "No page for eia861 green_pricing_eia861 2018\n",
      "Loading dataframe for eia861 mergers_eia861 2010\n",
      "Loading dataframe for eia861 mergers_eia861 2011\n",
      "Loading dataframe for eia861 mergers_eia861 2012\n",
      "Loading dataframe for eia861 mergers_eia861 2013\n",
      "Loading dataframe for eia861 mergers_eia861 2014\n",
      "Loading dataframe for eia861 mergers_eia861 2015\n",
      "Loading dataframe for eia861 mergers_eia861 2016\n",
      "Loading dataframe for eia861 mergers_eia861 2017\n",
      "Loading dataframe for eia861 mergers_eia861 2018\n",
      "Loading dataframe for eia861 net_metering_eia861 2010\n",
      "Loading dataframe for eia861 net_metering_eia861 2011\n",
      "Loading dataframe for eia861 net_metering_eia861 2012\n",
      "Loading dataframe for eia861 net_metering_eia861 2013\n",
      "Loading dataframe for eia861 net_metering_eia861 2014\n",
      "Loading dataframe for eia861 net_metering_eia861 2015\n",
      "Loading dataframe for eia861 net_metering_eia861 2016\n",
      "Loading dataframe for eia861 net_metering_eia861 2017\n",
      "Loading dataframe for eia861 net_metering_eia861 2018\n",
      "No page for eia861 non_net_metering_eia861 2010\n",
      "No page for eia861 non_net_metering_eia861 2011\n",
      "No page for eia861 non_net_metering_eia861 2012\n",
      "No page for eia861 non_net_metering_eia861 2013\n",
      "No page for eia861 non_net_metering_eia861 2014\n",
      "No page for eia861 non_net_metering_eia861 2015\n",
      "Loading dataframe for eia861 non_net_metering_eia861 2016\n",
      "Loading dataframe for eia861 non_net_metering_eia861 2017\n",
      "Loading dataframe for eia861 non_net_metering_eia861 2018\n",
      "Loading dataframe for eia861 operational_data_eia861 2010\n",
      "Loading dataframe for eia861 operational_data_eia861 2011\n",
      "Loading dataframe for eia861 operational_data_eia861 2012\n",
      "Loading dataframe for eia861 operational_data_eia861 2013\n",
      "Loading dataframe for eia861 operational_data_eia861 2014\n",
      "Loading dataframe for eia861 operational_data_eia861 2015\n",
      "Loading dataframe for eia861 operational_data_eia861 2016\n",
      "Loading dataframe for eia861 operational_data_eia861 2017\n",
      "Loading dataframe for eia861 operational_data_eia861 2018\n",
      "No page for eia861 reliability_eia861 2010\n",
      "No page for eia861 reliability_eia861 2011\n",
      "No page for eia861 reliability_eia861 2012\n",
      "Loading dataframe for eia861 reliability_eia861 2013\n",
      "Loading dataframe for eia861 reliability_eia861 2014\n",
      "Loading dataframe for eia861 reliability_eia861 2015\n",
      "Loading dataframe for eia861 reliability_eia861 2016\n",
      "Loading dataframe for eia861 reliability_eia861 2017\n",
      "Loading dataframe for eia861 reliability_eia861 2018\n",
      "Loading dataframe for eia861 sales_eia861 2010\n",
      "Loading dataframe for eia861 sales_eia861 2011\n",
      "Loading dataframe for eia861 sales_eia861 2012\n",
      "Loading dataframe for eia861 sales_eia861 2013\n",
      "Loading dataframe for eia861 sales_eia861 2014\n",
      "Loading dataframe for eia861 sales_eia861 2015\n",
      "Loading dataframe for eia861 sales_eia861 2016\n",
      "Loading dataframe for eia861 sales_eia861 2017\n",
      "Loading dataframe for eia861 sales_eia861 2018\n",
      "Loading dataframe for eia861 service_territory_eia861 2010\n",
      "Loading dataframe for eia861 service_territory_eia861 2011\n",
      "Loading dataframe for eia861 service_territory_eia861 2012\n",
      "Loading dataframe for eia861 service_territory_eia861 2013\n",
      "Loading dataframe for eia861 service_territory_eia861 2014\n",
      "Loading dataframe for eia861 service_territory_eia861 2015\n",
      "Loading dataframe for eia861 service_territory_eia861 2016\n",
      "Loading dataframe for eia861 service_territory_eia861 2017\n",
      "Loading dataframe for eia861 service_territory_eia861 2018\n",
      "No page for eia861 short_form_eia861 2010\n",
      "No page for eia861 short_form_eia861 2011\n",
      "Loading dataframe for eia861 short_form_eia861 2012\n",
      "Loading dataframe for eia861 short_form_eia861 2013\n",
      "Loading dataframe for eia861 short_form_eia861 2014\n",
      "Loading dataframe for eia861 short_form_eia861 2015\n",
      "Loading dataframe for eia861 short_form_eia861 2016\n",
      "Loading dataframe for eia861 short_form_eia861 2017\n",
      "Loading dataframe for eia861 short_form_eia861 2018\n",
      "Loading dataframe for eia861 utility_data_eia861 2010\n",
      "Loading dataframe for eia861 utility_data_eia861 2011\n",
      "Loading dataframe for eia861 utility_data_eia861 2012\n",
      "Loading dataframe for eia861 utility_data_eia861 2013\n",
      "Loading dataframe for eia861 utility_data_eia861 2014\n",
      "Loading dataframe for eia861 utility_data_eia861 2015\n",
      "Loading dataframe for eia861 utility_data_eia861 2016\n",
      "Loading dataframe for eia861 utility_data_eia861 2017\n",
      "Loading dataframe for eia861 utility_data_eia861 2018\n",
      "No years given. Not extracting eia923 spreadsheet data.\n",
      "No raw EIA 860 dataframes found. Not transforming EIA 860.\n",
      "Transforming raw EIA 861 DataFrames for service_territory_eia861 concatenated across all years.\n",
      "Assigned state FIPS codes for 100.00% of records.\n",
      "Assigned county FIPS codes for 99.88% of records.\n",
      "Transforming raw EIA 861 DataFrames for balancing_authority_eia861 concatenated across all years.\n",
      "Started with 9465 missing BA Codes out of 10725 records (88.25%)\n",
      "Ended with 1745 missing BA Codes out of 10725 records (16.27%)\n",
      "Transforming raw EIA 861 DataFrames for sales_eia861 concatenated across all years.\n",
      "Tidying the EIA 861 Sales table.\n",
      "Dropped 715 duplicate records from EIA 861 sales table, out of a total of 142020 records (0.5035% of all records). \n",
      "Ensuring raw columns are type compatible.\n",
      "Performing value transformations on EIA 861 Sales table.\n",
      "Transforming raw EIA 861 DataFrames for demand_response_eia861 concatenated across all years.\n",
      "Tidying the EIA 861 Demand Response table.\n",
      "Dropped 64 duplicate records from EIA 861 demand response table, out of a total of 10644 records (0.6013% of all records). \n",
      "Ensuring raw columns are type compatible.\n",
      "Performing value transformations on EIA 861 Sales table.\n",
      "No raw EIA 923 DataFrames found. Not transforming EIA 923.\n",
      "Converting the dtypes of: service_territory_eia861\n",
      "Converting the dtypes of: balancing_authority_eia861\n",
      "Converting the dtypes of: sales_eia861\n",
      "Converting the dtypes of: demand_response_eia861\n",
      "CPU times: user 1min 2s, sys: 814 ms, total: 1min 2s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eia_years = list(range(2010, 2019))\n",
    "eia_inputs = {\n",
    "    \"eia860_years\": [],\n",
    "    \"eia860_tables\": pudl.constants.pudl_tables[\"eia860\"],\n",
    "    \"eia861_years\": eia_years,\n",
    "    \"eia861_tables\": pudl.constants.pudl_tables[\"eia861\"],\n",
    "    \"eia923_years\": [],\n",
    "    \"eia923_tables\": pudl.constants.pudl_tables[\"eia923\"],\n",
    "}\n",
    "eia860_raw_dfs, eia861_raw_dfs, eia923_raw_dfs, eia_transformed_dfs = test_etl_eia(eia_inputs=eia_inputs, pudl_settings=pudl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check Data\n",
    "If there's any validation that can be done on the data which you've loaded to flag if/when it is inappropriate for the analysis that follows, do it here. If you find the data is unusable, use `assert` statements or `raise` Exceptions to stop the notebook from proceeding, and indicate what the problem is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advanced_metering_infrastructure_eia861',\n",
       " 'balancing_authority_eia861',\n",
       " 'demand_response_eia861',\n",
       " 'demand_side_management_eia861',\n",
       " 'distributed_generation_eia861',\n",
       " 'distribution_systems_eia861',\n",
       " 'dynamic_pricing_eia861',\n",
       " 'frame_eia861',\n",
       " 'green_pricing_eia861',\n",
       " 'mergers_eia861',\n",
       " 'net_metering_eia861',\n",
       " 'non_net_metering_eia861',\n",
       " 'operational_data_eia861',\n",
       " 'reliability_eia861',\n",
       " 'sales_eia861',\n",
       " 'service_territory_eia861',\n",
       " 'short_form_eia861',\n",
       " 'utility_data_eia861']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(eia861_raw_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service_territory_eia861',\n",
       " 'balancing_authority_eia861',\n",
       " 'sales_eia861',\n",
       " 'demand_response_eia861']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(eia_transformed_dfs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Data Wrangling\n",
    "Once all of the data is loaded and looks like it's in good shape, do any initial wrangling that's specific to this particular analysis. This should mostly make use of the higher level functions which were defined above. If this step takes a while, don't be shy about producing `logging` outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Response"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization\n",
    "* Now that you've got the required data in a usable form, you can tell the story of your analysis through a mix of visualizations, and further data wrangling steps.\n",
    "* This narrative should be readable, with figures that have titles, legends, and labeled axes as appropriate so others can understand what you're showing them.\n",
    "* The code should be concise and make use of the parameters and functions which you've defined above when possible. Functions should contain comprehensible chunks of work that make sense as one step in the story of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
